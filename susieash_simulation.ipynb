{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuSiE.ash Simulation Scripts\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Goal & Setup](#goal)\n",
    "- [LD Block Extraction](#ld-blocks-extraction-for-both-sparse-and-oligogenic-settings)\n",
    "- [Helper Functions for Main Simulation](#helper-functions-for-main-simulation-scripts)\n",
    "- [Sparse Simulation](#sparse-simulation-script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "We aim to show the performance SuSiE, SuSiE.ash (Marginal & Random Effects), SuSiE-inf, and Fineboost in various realistic expression quantitative trait loci (eQTL) sparse and oligogenic simulation settings.\n",
    "\n",
    "## Sparse Simulation Setup\n",
    "\n",
    "The sparse simulations use data from UK Biobank where we randomly sampled 150 LD blocks, for each simulation setting, across chromosomes 1-22 and derive the associated genotype matrices to serve as the basis for our simulations. For the first simulation setting, we take the first 1000 variants and 1500 individuals, and for the second simulation setting, we take between 3000 to 12000 variants and 1500 individauls. For the first simulation setting, we run all pairwise combinations of the number of effect variables = {1, 2, 3, 4, 5} and heritability = {0.05, 0.10, 0.20, 0.40} twice for each genotype matrix, resulting in a total of 2 x 150 x 5 x 4 = 6000 data sets for the first simulation setting. For the second simulation setting, we simply set the number of effect variables = 10 and the heritability = 0.30 and run this scenario twice for each genotype matrix, resulting in a total of 2 x 150 = 300 data sets. All LD blocks have a missing rate < 0.05, minor allele frequency (MAF) > 0.05, filter out all variants with zero (or near-zero variance), and utilize mean imputation for any missing data. Finally, we will repeat the first and second simulation setting for three types of LD structures between causal variants: i) no LD among causal variants (|r| < 0.05), ii) minimal LD (|r| < 0.30) among causal variants, and iii) randomly assigned LD between causal variants.\n",
    "\n",
    "## Oligogenic Simulation Setup\n",
    "\n",
    "Similar to the sparse simulations, the oligogenic simulations also use data from UK Biobank. We randomly sampled 150 LD blocks across chromosomes 1-22 and derive the associated genotype matrices to serve as the basis for our simulations. We will take between 5000 and 8000 variants and 1500 individuals, and will run three separate levels of heritability = {0.15, 0.30, 0.50}. For each level, we will utilize each genotype matrix twice, resulting in a total of 3 x 2 x 150 = 900 data sets. We applied the same QC measures as the sparse simulations, however, we will only randomly assign LD between causal variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LD Blocks Extraction (for both Sparse and Oligogenic Settings)\n",
    "\n",
    "### Filter LD Blocks\n",
    "\n",
    "LD blocks have already passed preliminary QC filters, such as filtering out variants with low MAF (< 0.05) and high missing rate (> 0.10). However, we will apply additional QC measures and refine the genotype matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# note you will need to set the proper Access Key ID and Secret Access Key ID to the S3 bucket.\n",
    "Sys.setenv(\"AWS_ACCESS_KEY_ID\" = \"KEY\",\n",
    "           \"AWS_SECRET_ACCESS_KEY\" = \"SECRET KEY\",\n",
    "           \"AWS_DEFAULT_REGION\" = \"us-east-1\")\n",
    "\n",
    "library(aws.s3)\n",
    "library(stringr)\n",
    "library(tidyverse)\n",
    "\n",
    "output_folder <- \"ftp_fgc_xqtl/interactive_sessions/apm2217/susie-ash-data/UKBB_data\"\n",
    "output_files <- get_bucket(bucket = \"statfungen\", prefix = output_folder, max = Inf)\n",
    "\n",
    "# filter by log files\n",
    "log_files <- sapply(output_files, function(x) x$Key)\n",
    "log_files <- log_files[grep(\"\\\\.log$\", log_files)]\n",
    "\n",
    "# initialize df\n",
    "results_df <- data.frame(\n",
    "  LD_Block = character(),\n",
    "  Variants_Passed_QC = integer(),\n",
    "  Genotyping_Rate = numeric(),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "# read each .log file\n",
    "for (log_file in log_files) {\n",
    "  # Read the .log file directly from S3 into R\n",
    "  log_content <- s3read_using(\n",
    "    FUN = readLines,\n",
    "    object = log_file,\n",
    "    bucket = \"statfungen\"\n",
    "  )\n",
    "  \n",
    "  # extract the number of variants that passed QC\n",
    "  variants_line <- grep(\"variants and .* people pass filters and QC\", log_content, value = TRUE)\n",
    "  variants_passed <- as.integer(str_extract(variants_line, \"\\\\d+\"))\n",
    "  \n",
    "  # extract the genotyping rate\n",
    "  geno_rate_line <- grep(\"Total genotyping rate is\", log_content, value = TRUE)\n",
    "  genotyping_rate <- as.numeric(str_extract(geno_rate_line, \"\\\\d+\\\\.\\\\d+\"))\n",
    "  \n",
    "  # get the LD block identifier from the file name\n",
    "  ld_block_id <- basename(log_file)\n",
    "  ld_block_id <- sub(\"\\\\.log$\", \"\", ld_block_id)\n",
    "  \n",
    "  # append the extracted data to the results data frame\n",
    "  results_df <- rbind(\n",
    "    results_df,\n",
    "    data.frame(\n",
    "      LD_Block = ld_block_id,\n",
    "      Variants_Passed_QC = variants_passed,\n",
    "      Genotyping_Rate = genotyping_rate,\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "  )\n",
    "}\n",
    "\n",
    "# filter for at least p variants and missing rate < 0.05\n",
    "filtered_ld_blocks <- subset(\n",
    "  results_df,\n",
    "  Variants_Passed_QC >= 1000 &   # sparse setting 1\n",
    "  # Variants_Passed_QC >= 3000 & # sparse setting 2\n",
    "  # Variants_Passed_QC >= 5000 & # oligogenic setting\n",
    "    Genotyping_Rate >= 0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Sample 150 LD Blocks from List and Generate Script to Run Genotype Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(6868)   # Sparse Simulation 1 Seed\n",
    "# set.seed(8686) # Sparse Simulation 2 Seed\n",
    "# set.seed(6688) # Oligogenic Simulation Seed\n",
    "sampled_blocks <- sample(filtered_ld_blocks$LD_Block, size = 150, replace = FALSE)\n",
    "\n",
    "chromosome_ids <- str_extract(sampled_blocks, \"(?<=chr)[^_]+\")\n",
    "\n",
    "chromosome_counts <- table(chromosome_ids)\n",
    "chromosome_df <- as.data.frame(chromosome_counts)\n",
    "colnames(chromosome_df) <- c(\"Chromosome\", \"Count\")\n",
    "\n",
    "\n",
    "# function to map chromosome identifiers to numeric values\n",
    "map_chr_to_num <- function(chr) {\n",
    "  if (chr %in% as.character(1:22)) {\n",
    "    return(as.numeric(chr))\n",
    "  } else {\n",
    "    return(NA)\n",
    "  }\n",
    "}\n",
    "\n",
    "# apply the function to create a numeric representation\n",
    "chromosome_df$Chromosome_numeric <- sapply(chromosome_df$Chromosome, map_chr_to_num)\n",
    "chromosome_df <- chromosome_df[order(chromosome_df$Chromosome_numeric), ]\n",
    "chromosome_df$Chromosome <- factor(chromosome_df$Chromosome, levels = chromosome_df$Chromosome)\n",
    "\n",
    "# create the bar plot of distribution chromosome counts\n",
    "ggplot(chromosome_df, aes(x = factor(Chromosome, levels = c(seq(1,22))), y = Count)) +\n",
    "  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n",
    "  xlab(\"Chromosome\") +\n",
    "  ylab(\"Number of LD Blocks Sampled\") +\n",
    "  ggtitle(\"Distribution of Sampled LD Blocks Across Chromosomes\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# create the commands_to_submit.txt file\n",
    "commands_file <- \"commands_to_submit.txt\"\n",
    "file_conn <- file(commands_file, open = \"w\")\n",
    "\n",
    "# iterate over each LD block and write commands to the file\n",
    "for (ld_block_name in sampled_blocks) {\n",
    "  # create the command\n",
    "  command <- paste0(\"Rscript /home/apm2217/data/process_ld_block.R \", ld_block_name)\n",
    "\n",
    "  # write the command to the file\n",
    "  writeLines(command, file_conn)\n",
    "}\n",
    "\n",
    "# close the file connection\n",
    "close(file_conn)\n",
    "\n",
    "cat(\"Commands file 'commands_to_submit.txt' created successfully.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to Extract Genotype Matrices\n",
    "\n",
    "Below is the \"process_ld_block.R\" script that our \"commands_to_submit.txt\" file references. We will submit each of these commands to the cloud for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "library(bigsnpr)\n",
    "\n",
    "# get the LD block name from command-line arguments\n",
    "args <- commandArgs(trailingOnly = TRUE)\n",
    "if (length(args) == 0) {\n",
    "  stop(\"No LD block name provided. Usage: Rscript process_ld_block.R ld_block_name\")\n",
    "}\n",
    "ld_block_name <- args[1]\n",
    "\n",
    "# define your data and output paths\n",
    "data_path <- \"/home/apm2217/data/\" # this points to the S3 bucket containing the UKBB data\n",
    "output_path <- \"/home/apm2217/output/\" \n",
    "\n",
    "# function to process a single LD block\n",
    "process_ld_block <- function(ld_block_name) {\n",
    "  message(\"Processing LD block: \", ld_block_name)\n",
    "\n",
    "  # define file paths\n",
    "  bedfile <- file.path(data_path, paste0(ld_block_name, \".bed\"))\n",
    "  bimfile <- file.path(data_path, paste0(ld_block_name, \".bim\"))\n",
    "  famfile <- file.path(data_path, paste0(ld_block_name, \".fam\"))\n",
    "\n",
    "  # check if files exist\n",
    "  if (!file.exists(bedfile) || !file.exists(bimfile) || !file.exists(famfile)) {\n",
    "    stop(\"One or more PLINK files for \", ld_block_name, \" are missing.\")\n",
    "  }\n",
    "\n",
    "  # create a temporary directory for processing\n",
    "  temp_dir <- tempfile(pattern = \"temp_ld_block_\")\n",
    "  dir.create(temp_dir)\n",
    "\n",
    "  # Copy PLINK files to temporary directory\n",
    "  file.copy(bedfile, temp_dir)\n",
    "  file.copy(bimfile, temp_dir)\n",
    "  file.copy(famfile, temp_dir)\n",
    "\n",
    "  # define paths to copied files\n",
    "  temp_bedfile <- file.path(temp_dir, basename(bedfile))\n",
    "  temp_bimfile <- file.path(temp_dir, basename(bimfile))\n",
    "  temp_famfile <- file.path(temp_dir, basename(famfile))\n",
    "\n",
    "  # read PLINK files using bigsnpr\n",
    "  backingfile <- file.path(temp_dir, paste0(ld_block_name, \"_bk\"))\n",
    "\n",
    "  # convert PLINK files to bigSNP format (creates .rds and .bk files)\n",
    "  snp_readBed(temp_bedfile, backingfile = backingfile)\n",
    "\n",
    "  # attach the bigSNP object\n",
    "  obj.bigSNP <- snp_attach(paste0(backingfile, \".rds\"))\n",
    "  G <- obj.bigSNP$genotypes\n",
    "  sample_ids <- obj.bigSNP$fam$sample.ID\n",
    "  variant_ids <- obj.bigSNP$map$marker.ID\n",
    "\n",
    "  # check dimensions\n",
    "  num_individuals <- nrow(G)\n",
    "  num_variants <- ncol(G)\n",
    "\n",
    "  message(\"Number of individuals: \", num_individuals)\n",
    "  message(\"Number of variants: \", num_variants)\n",
    "\n",
    "  # extract the first n individuals\n",
    "  num_individuals_to_sample <- 1500 # \n",
    "  sampled_individuals <- 1:num_individuals_to_sample\n",
    "\n",
    "  # extract the first p variants\n",
    "\n",
    "  ## Sparse Setting 1\n",
    "  num_variants_to_sample <- 1000 \n",
    "\n",
    "  ## Sparse Setting 2\n",
    "  # set.seed(8686)\n",
    "  # num_variants_to_sample <- round(runif(1, 3000, min(num_variants,12000)))\n",
    "\n",
    "  ## Oligogenic Setting \n",
    "  # set.seed(6688)\n",
    "  # num_variants_to_sample <- round(runif(1, 5000, min(num_variants,8000)))\n",
    "  sampled_variants <- 1:num_variants_to_sample\n",
    "\n",
    "  # subset the genotype matrix\n",
    "  G_sub <- G[sampled_individuals, sampled_variants]\n",
    "\n",
    "  # Create a list to save\n",
    "  genotype_data <- list(\n",
    "    genotypes = G_sub,\n",
    "    sample_ids = sample_ids[sampled_individuals],\n",
    "    variant_ids = variant_ids[sampled_variants],\n",
    "    chromosome = obj.bigSNP$map$chromosome[sampled_variants],\n",
    "    physical_pos = obj.bigSNP$map$physical.pos[sampled_variants],\n",
    "    alleles = obj.bigSNP$map[, c(\"allele1\", \"allele2\")][sampled_variants, ]\n",
    "  )\n",
    "\n",
    "  # save the genotype data to an RDS file in the output directory\n",
    "  output_file <- file.path(output_path, paste0(ld_block_name, \"_matrix.rds\"))\n",
    "  saveRDS(genotype_data, file = output_file)\n",
    "\n",
    "  message(\"Saved processed data to \", output_file)\n",
    "\n",
    "  # clean up temporary files\n",
    "  unlink(temp_dir, recursive = TRUE)\n",
    "\n",
    "  message(\"Completed processing for \", ld_block_name)\n",
    "}\n",
    "\n",
    "# call the function with the provided LD block name\n",
    "process_ld_block(ld_block_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shell Script to Submit Cloud Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "username=apm2217\n",
    "./src/mm_batch.sh \\\n",
    "  --job-script ./commands_to_submit.txt \\\n",
    "  -c 4 -m 64 \\\n",
    "  --job-size 150 \\\n",
    "  --parallel-commands 4 \\\n",
    "  --mount statfungen/ftp_fgc_xqtl/interactive_sessions/$username/susie-ash-data/UKBB_data:/home/$username/data \\\n",
    "  --mount statfungen/ftp_fgc_xqtl/interactive_sessions/$username/sparse_LD_blocks_scenario_1:/home/$username/output \\\n",
    "  --mountOpt \"mode=r\" \"mode=rw\" \\\n",
    "  --cwd \"/home/$username/data\" \\\n",
    "  --imageVolSize 20 \\\n",
    "  --opcenter 3.82.198.55 \\\n",
    "  --no-fail-fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for QC & Precomputing Values for SuSiE.ash and SuSiE-inf\n",
    "\n",
    "For quality control, in addition to missing rate and MAF filters from earlier, we also use mean imputation for any missing data and remove variants with zero (or near-zero) variance. Additionally, SuSiE.ash and SuSiE-inf both can be drastically sped up if we use precomputed matrices for the LD matrix, eigen values/vectors, and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "library(Matrix)\n",
    "input_dir <- \"/home/apm2217/data\"   \n",
    "output_dir <- \"/home/apm2217/output\"\n",
    "\n",
    "args <- commandArgs(trailingOnly = TRUE)\n",
    "ld_block_names <- args\n",
    "\n",
    "# ensure output directory exists\n",
    "if (!dir.exists(output_dir)) {\n",
    "  dir.create(output_dir, recursive = TRUE)\n",
    "}\n",
    "\n",
    "# function to mean-impute missing values\n",
    "mean_impute <- function(geno) {\n",
    "  # Compute column-wise means excluding NAs\n",
    "  col_means <- apply(geno, 2, function(x) mean(x, na.rm = TRUE))\n",
    "\n",
    "  # replace NAs with the corresponding column mean\n",
    "  for (i in seq_along(col_means)) {\n",
    "    na_indices <- which(is.na(geno[, i]))\n",
    "    if (length(na_indices) > 0) {\n",
    "      geno[na_indices, i] <- col_means[i]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return(geno)\n",
    "}\n",
    "\n",
    "# function to process a single LD block\n",
    "process_ld_block <- function(ld_block_name) {\n",
    "  # construct the full path to the LD block file\n",
    "  input_file <- file.path(input_dir, paste0(ld_block_name, \"_matrix.rds\"))\n",
    "\n",
    "  # check if the input file exists\n",
    "  if (!file.exists(input_file)) {\n",
    "    cat(\"Input file does not exist:\", input_file, \"\\n\")\n",
    "    return(NULL)\n",
    "  }\n",
    "\n",
    "  cat(\"Processing LD block file:\", input_file, \"\\n\")\n",
    "\n",
    "  # load the LD block from the local file system\n",
    "  ld_block_obj <- readRDS(input_file)\n",
    "\n",
    "  # check if 'genotypes' exist in the LD block object\n",
    "  if (!\"genotypes\" %in% names(ld_block_obj)) {\n",
    "    cat(\"The LD block object does not contain 'genotypes'. Skipping.\\n\")\n",
    "    return(NULL)\n",
    "  }\n",
    "\n",
    "  # extract and mean-impute the genotype matrix\n",
    "  X <- mean_impute(ld_block_obj$genotypes)\n",
    "\n",
    "  # remove columns with zero or near-zero variance\n",
    "  sd_X <- apply(X, 2, sd)\n",
    "  threshold <- 1e-8  # Adjust as needed\n",
    "  columns_to_remove <- which(sd_X < threshold)\n",
    "\n",
    "  if (length(columns_to_remove) > 0) {\n",
    "    cat(\"Removing\", length(columns_to_remove), \"columns with zero or near-zero variance.\\n\")\n",
    "    X <- X[, -columns_to_remove, drop = FALSE]\n",
    "  }\n",
    "\n",
    "  if (ncol(X) == 0) {\n",
    "    cat(\"No columns left after removing zero or near-zero variance columns. Skipping.\\n\")\n",
    "    return(NULL)\n",
    "  }\n",
    "\n",
    "  # scale the genotype matrix\n",
    "  X_scaled <- scale(X)\n",
    "\n",
    "  # compute XtX\n",
    "  cat(\"Computing XtX\\n\")\n",
    "  XtX <- crossprod(X_scaled)\n",
    "\n",
    "  # compute LD matrix\n",
    "  n_samples <- nrow(X)\n",
    "  LD <- XtX / n_samples\n",
    "\n",
    "  # compute eigenvalues and eigenvectors\n",
    "  cat(\"Computing eigenvalues of LD matrix\\n\")\n",
    "  eig <- eigen(LD, symmetric = TRUE)\n",
    "  V <- eig$vectors\n",
    "  Dsq <- pmax(n_samples * eig$values, 0)\n",
    "\n",
    "  # compute VtXt\n",
    "  VtXt <- t(V) %*% t(X_scaled)\n",
    "\n",
    "  # prepare the result list\n",
    "  result <- list(\n",
    "    X = X,        # unscaled processed genotype matrix\n",
    "    XtX = XtX,\n",
    "    LD = LD,\n",
    "    V = V,\n",
    "    Dsq = Dsq,\n",
    "    VtXt = VtXt\n",
    "  )\n",
    "\n",
    "  # Construct the output file path\n",
    "  output_file <- file.path(output_dir, paste0(ld_block_name, \"_processed.rds\"))\n",
    "  cat(\"Saving processed matrices to:\", output_file, \"\\n\")\n",
    "\n",
    "  # Save the result to the output directory\n",
    "  saveRDS(result, file = output_file)\n",
    "}\n",
    "\n",
    "# Process each LD block\n",
    "for (ld_block_name in ld_block_names) {\n",
    "  process_ld_block(ld_block_name)\n",
    "}\n",
    "\n",
    "cat(\"All LD blocks have been processed.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Commands Script\n",
    "\n",
    "This requires the same `sampled_blocks` object from earlier, a vector containing the strings of the LD blocks sampled. This can be submitted to cloud using same shell script from above just with adjusted input and output folder pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# path to the processing script\n",
    "processing_script <- \"/home/apm2217/data/LD_blocks_precomputations.R\"\n",
    "\n",
    "# create the commands_to_submit.txt file\n",
    "commands_file <- \"commands_to_submit.txt\"\n",
    "file_conn <- file(commands_file, open = \"w\")\n",
    "\n",
    "# iterate over each LD block and write commands to the file\n",
    "for (ld_block_name in sampled_blocks) {\n",
    "  # Create the command to process this LD block\n",
    "  command <- paste(\n",
    "    \"Rscript\", processing_script, ld_block_name\n",
    "  )\n",
    "\n",
    "  # write the command to the file\n",
    "  writeLines(command, file_conn)\n",
    "}\n",
    "\n",
    "# close the file connection\n",
    "close(file_conn)\n",
    "\n",
    "cat(\"Commands file 'commands_to_submit.txt' created successfully.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Main Simulation Scripts\n",
    "\n",
    "### Phenotype Generation\n",
    "\n",
    "#### Sparse Simulation\n",
    "\n",
    "Below is the function used to generate our sparse data expression levels. The user must enter in a i) genotype matrix, ii) number of effect variables, iii) desired heritability level, iv) ld_mode (this refers to the LD between causal variants and can either be `random`, `minimal` (|r| < 0.05), or `low` |r| < 0.30). Optionally, the user can input their own seed and LD matrix (to save on computation time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# sparse_data_generation.R\n",
    "# ================================\n",
    "\n",
    "library(simxQTL)\n",
    "\n",
    "# helper function to sample causal indices that satisfy an LD threshold\n",
    "get_valid_causal <- function(G, ncausal, ld_threshold, max_attempts = 10000, ld_matrix = NULL) {\n",
    "  snp_indices <- seq_len(ncol(G))\n",
    "  for (attempt in 1:max_attempts) {\n",
    "    causal_indices <- sort(sample(snp_indices, ncausal))\n",
    "    if (!is.null(ld_matrix)) {\n",
    "      # use the provided LD matrix (assumed to already be absolute)\n",
    "      corr_mat <- ld_matrix[causal_indices, causal_indices]\n",
    "    } else {\n",
    "      # compute correlation matrix and take absolute values\n",
    "      corr_mat <- abs(cor(G[, causal_indices]))\n",
    "    }\n",
    "    # set diagonal and lower triangle to zero (only off-diagonals matter)\n",
    "    corr_mat[lower.tri(corr_mat, diag = TRUE)] <- 0\n",
    "    if (max(corr_mat) < ld_threshold) {\n",
    "      return(causal_indices)\n",
    "    }\n",
    "  }\n",
    "  stop(\"Could not find a set of causal variants with LD (|r|) below \", ld_threshold, \" after \", max_attempts, \" attempts.\")\n",
    "}\n",
    "\n",
    "generate_sparse_eqtl_data <- function(X, K = 10, h2 = 0.3, seed = NULL,\n",
    "                                      ld_mode = \"random\", ld_matrix = NULL, max_attempts = 10000) {\n",
    "  if (!is.null(seed)) set.seed(seed)\n",
    "\n",
    "  n_samples <- nrow(X)\n",
    "  n_features <- ncol(X)\n",
    "\n",
    "  # parse K to get the number of causal SNPs\n",
    "  causal_info <- parse_num_causal_snps(as.character(K))\n",
    "  if (causal_info$is_pct) {\n",
    "    n_causal <- max(1, round(causal_info$value * n_features))\n",
    "  } else {\n",
    "    n_causal <- min(causal_info$value, n_features)\n",
    "  }\n",
    "\n",
    "  # determine causal indices based on ld_mode\n",
    "  if (ld_mode == \"random\") {\n",
    "    causal_indices <- sort(sample(seq_len(n_features), n_causal, replace = FALSE))\n",
    "  } else if (ld_mode == \"minimal_ld\") {\n",
    "    causal_indices <- get_valid_causal(G = X, ncausal = n_causal,\n",
    "                                       ld_threshold = 0.05, max_attempts = max_attempts,\n",
    "                                       ld_matrix = ld_matrix)\n",
    "  } else if (ld_mode == \"low_ld\") {\n",
    "    causal_indices <- get_valid_causal(G = X, ncausal = n_causal,\n",
    "                                       ld_threshold = 0.30, max_attempts = max_attempts,\n",
    "                                       ld_matrix = ld_matrix)\n",
    "  } else {\n",
    "    stop(\"Invalid ld_mode. Choose from 'random', 'minimal_ld', or 'low_ld'.\")\n",
    "  }\n",
    "\n",
    "  # create beta vector and assign effect sizes from N(0, 0.6^2) for the causal SNPs\n",
    "  beta <- rep(0, n_features)\n",
    "  beta[causal_indices] <- rnorm(length(causal_indices), mean = 0, sd = 0.6)\n",
    "\n",
    "  # compute the latent genetic effect\n",
    "  g <- as.vector(X %*% beta)\n",
    "\n",
    "  # generate phenotype using the GitHub simulate_polygenic_trait function\n",
    "  y <- simulate_polygenic_trait(g, h2)\n",
    "\n",
    "  # compute estimated heritability\n",
    "  var_g <- var(g)\n",
    "  var_e <- var(y - g)\n",
    "  h2_estimated <- var_g / (var_g + var_e)\n",
    "\n",
    "  return(list(\n",
    "    X = X,\n",
    "    y = as.vector(y),\n",
    "    beta = beta,\n",
    "    causal_indices = causal_indices,\n",
    "    var_epsilon = var_e,\n",
    "    h2_input = h2,\n",
    "    h2_estimated = h2_estimated\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oligogenic Simulation\n",
    "\n",
    "Note that the `generate_eqtl_data()` function is included in the simxQTL repo, however, it is included here for completeness. We also included the `is_causal()` function which assigns variants that meet a user-defined PVE threshold to be causal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# oligogenic_data_generation.R\n",
    "# ================================\n",
    "\n",
    "library(simxQTL)\n",
    "\n",
    "generate_eqtl_data <- function(G,\n",
    "                               h2_total = 0.3,\n",
    "                               prop_h2_sparse = 0.65,\n",
    "                               prop_h2_oligogenic = 0.20,\n",
    "                               prop_h2_infinitesimal = 0.15,\n",
    "                               prop_h2_sentinel = 0.7,\n",
    "                               n_oligogenic = 20,\n",
    "                               mixture_props = c(0.75, 0.25),\n",
    "                               mixture_sds = c(0.0025, 0.005),\n",
    "                               n_other_sparse = 2,\n",
    "                               standardize = TRUE,\n",
    "                               seed = NULL) {\n",
    "  # Minimal input validation for proportions\n",
    "  if (abs(prop_h2_sparse + prop_h2_oligogenic + prop_h2_infinitesimal - 1) > 1e-6) {\n",
    "    stop(\"The sum of prop_h2_sparse, prop_h2_oligogenic, and prop_h2_infinitesimal must equal 1.\")\n",
    "  }\n",
    "  if (abs(sum(mixture_props) - 1) > 1e-6) {\n",
    "    stop(\"mixture_props must sum to 1.\")\n",
    "  }\n",
    "  \n",
    "  if (!is.null(seed)) set.seed(seed)\n",
    "  \n",
    "  # Standardize genotype matrix if requested\n",
    "  if (standardize) {\n",
    "    G <- scale(G)\n",
    "  }\n",
    "  \n",
    "  n_samples <- nrow(G)\n",
    "  n_features <- ncol(G)\n",
    "  \n",
    "  # Allocate heritability components\n",
    "  h2_sparse <- h2_total * prop_h2_sparse\n",
    "  h2_oligogenic <- h2_total * prop_h2_oligogenic\n",
    "  h2_infinitesimal <- h2_total * prop_h2_infinitesimal\n",
    "  \n",
    "  # 1. Sparse Effects (sentinel + additional sparse SNPs)\n",
    "  sparse_res <- simulate_sparse_effects(G, h2_sparse, prop_h2_sentinel, n_other_sparse)\n",
    "  beta_sparse <- sparse_res$beta\n",
    "  sentinel_index <- sparse_res$sentinel_index\n",
    "  other_sparse_indices <- sparse_res$other_sparse_indices\n",
    "  sparse_indices <- c(sentinel_index, other_sparse_indices)\n",
    "  \n",
    "  # 2. Oligogenic Effects\n",
    "  non_sparse_indices <- setdiff(1:n_features, sparse_indices)\n",
    "  oligo_res <- simulate_oligogenic_effects(G, h2_oligogenic, n_oligogenic, mixture_props, mixture_sds, non_sparse_indices)\n",
    "  beta_oligo <- oligo_res$beta\n",
    "  oligogenic_indices <- oligo_res$oligogenic_indices\n",
    "  \n",
    "  # 3. Infinitesimal Effects (remaining SNPs)\n",
    "  infinitesimal_indices <- setdiff(non_sparse_indices, oligogenic_indices)\n",
    "  beta_inf <- simulate_infinitesimal_effects(G, h2_infinitesimal, infinitesimal_indices)\n",
    "  \n",
    "  # Combine all effect components\n",
    "  beta <- beta_sparse + beta_oligo + beta_inf\n",
    "  \n",
    "  # Generate latent genetic component and phenotype\n",
    "  g <- as.vector(G %*% beta)\n",
    "  var_g <- var(g)\n",
    "  var_epsilon <- var_g * (1 - h2_total) / h2_total\n",
    "  epsilon <- rnorm(n_samples, 0, sqrt(var_epsilon))\n",
    "  y <- g + epsilon\n",
    "  \n",
    "  # Calculate realized heritability components\n",
    "  var_y <- var(y)\n",
    "  h2_sentinel_actual <- var(G[, sentinel_index] * beta[sentinel_index]) / var_y\n",
    "  h2_sparse_actual <- var(as.vector(G[, sparse_indices] %*% beta[sparse_indices])) / var_y\n",
    "  h2_oligogenic_actual <- var(as.vector(G[, oligogenic_indices] %*% beta[oligogenic_indices])) / var_y\n",
    "  h2_infinitesimal_actual <- var(as.vector(G[, infinitesimal_indices] %*% beta_inf[infinitesimal_indices])) / var_y\n",
    "  h2_total_actual <- var(as.vector(G %*% beta)) / var_y\n",
    "  \n",
    "  return(list(\n",
    "    G = G,                # Standardized genotype matrix\n",
    "    y = y,                # Simulated phenotype (on its generated scale)\n",
    "    beta = beta,\n",
    "    h2_total = h2_total_actual,\n",
    "    h2_sparse = h2_sparse_actual,\n",
    "    h2_sentinel = h2_sentinel_actual,\n",
    "    h2_oligogenic = h2_oligogenic_actual,\n",
    "    h2_infinitesimal = h2_infinitesimal_actual,\n",
    "    sentinel_index = sentinel_index,\n",
    "    other_sparse_indices = other_sparse_indices,\n",
    "    oligogenic_indices = oligogenic_indices,\n",
    "    infinitesimal_indices = infinitesimal_indices,\n",
    "    residual_variance = var_epsilon\n",
    "  ))\n",
    "}\n",
    "\n",
    "# function to identify causal SNPs based on PVE threshold\n",
    "is_causal <- function(beta, residual_variance, pve_threshold) {\n",
    "\n",
    "  # compute variance explained by each SNP (since Var(X_j) = 1), assumes standardized genotype matrix\n",
    "  variance_explained <- beta^2\n",
    "\n",
    "  # compute total genetic variance\n",
    "  var_g <- sum(variance_explained)\n",
    "\n",
    "  # compute total variance (genetic variance + residual variance)\n",
    "  total_variance <- var_g + residual_variance\n",
    "\n",
    "  # compute PVE for each SNP\n",
    "  proportion_var_explained <- variance_explained / total_variance\n",
    "\n",
    "  # define causal SNPs based on the current PVE threshold\n",
    "  causal_SNPs <- which(proportion_var_explained > pve_threshold)\n",
    "  return(causal = causal_SNPs)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Function to Run Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# run_methods.R\n",
    "# ================================\n",
    "# This file contains wrapper functions for running different methods:\n",
    "# - run_susie(): Standard SuSiE method.\n",
    "# - run_susie_ash(): SuSiE.ash (Marginal) using susie_ash_RE_Marg().\n",
    "# - run_susie_inf(): SuSiE-inf method.\n",
    "# - run_fineboost(): Fineboost using colocboost().\n",
    "\n",
    "\n",
    "# Wrapper for SuSiE\n",
    "run_susie <- function(data, L, intercept = TRUE, standardize = TRUE) {\n",
    "  cat(\"Starting SuSiE\\n\")\n",
    "  out <- susie(\n",
    "    X = data$X,\n",
    "    y = data$y,\n",
    "    L = L,\n",
    "    intercept = intercept,\n",
    "    standardize = standardize\n",
    "  )\n",
    "  return(out)\n",
    "}\n",
    "\n",
    "# Wrapper for SuSiE.ash (Marginal)\n",
    "run_susie_ash <- function(data, precomp, L, K.length, upper_bound, intercept = TRUE, standardize = TRUE) {\n",
    "  cat(\"Starting SuSiE.ash (Marginal)\\n\")\n",
    "\n",
    "  # Manually scale X and y if intercept or standardize is TRUE.\n",
    "  X_in <- if (intercept || standardize) scale(data$X, center = intercept, scale = standardize) else data$X\n",
    "  y_in <- if (intercept || standardize) scale(data$y, center = intercept, scale = standardize) else data$y\n",
    "\n",
    "  out <- susie_ash_RE_Marg(\n",
    "    X                = X_in,\n",
    "    y                = y_in,\n",
    "    L                = L,\n",
    "    verbose          = FALSE,\n",
    "    coverage         = 0.95,\n",
    "    XtX              = precomp$XtX,\n",
    "    LD               = precomp$LD,\n",
    "    V                = precomp$V,\n",
    "    Dsq              = precomp$Dsq,\n",
    "    VtXt             = precomp$VtXt,\n",
    "    update_ash_sigma = FALSE,\n",
    "    K.length         = K.length,\n",
    "    upper_bound      = upper_bound\n",
    "  )\n",
    "  return(out)\n",
    "}\n",
    "\n",
    "# Wrapper for SuSiE-inf\n",
    "run_susie_inf <- function(data, precomp, L, intercept = TRUE, standardize = TRUE) {\n",
    "  cat(\"Starting SuSiE-inf\\n\")\n",
    "\n",
    "  # Manually scale X and y if needed.\n",
    "  X_in <- if (intercept || standardize) scale(data$X, center = intercept, scale = standardize) else data$X\n",
    "  y_in <- if (intercept || standardize) scale(data$y, center = intercept, scale = standardize) else data$y\n",
    "\n",
    "  out <- susie_inf(\n",
    "    X       = X_in,\n",
    "    y       = y_in,\n",
    "    L       = L,\n",
    "    verbose = FALSE,\n",
    "    coverage = 0.95,\n",
    "    XtX     = precomp$XtX,\n",
    "    LD      = precomp$LD,\n",
    "    V       = precomp$V,\n",
    "    Dsq     = precomp$Dsq\n",
    "  )\n",
    "  return(out)\n",
    "}\n",
    "\n",
    "# Wrapper for Fineboost\n",
    "run_fineboost <- function(data, null_max, intercept = TRUE, standardize = TRUE) {\n",
    "  cat(\"Starting Fineboost\\n\")\n",
    "  out <- colocboost(\n",
    "    X              = data$X,\n",
    "    Y              = data$y,\n",
    "    check_null_max = null_max,\n",
    "    intercept      = intercept,\n",
    "    standardize    = standardize\n",
    "  )\n",
    "  return(out)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evalution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# evaluate_method_performance.R\n",
    "# ================================\n",
    "# This file defines a unified calc_metrics() function to compute:\n",
    "# - Average Credible Set (CS) Size\n",
    "# - Coverage (proportion of CSs capturing a causal variant)\n",
    "# - CS-based FDR and Recall\n",
    "#\n",
    "# The function adapts to different model outputs based on the provided method.\n",
    "\n",
    "calc_metrics <- function(mod, method, X, causal) {\n",
    "  # Define test.cs based on the method\n",
    "  if (method == \"susie\") {\n",
    "    test.cs <- susie_get_cs(mod, X = X, coverage = 0.95)$cs\n",
    "  } else if (method == \"fineboost\") {\n",
    "    test.cs <- mod$ucos_details$ucos$ucos_index\n",
    "  } else if (method %in% c(\"susie_ash\", \"susie_inf\")) {\n",
    "    test.cs <- mod$sets\n",
    "  } else {\n",
    "    stop(\"Unknown method specified for metric calculation.\")\n",
    "  }\n",
    "\n",
    "  # Initialize metrics\n",
    "  cs_size   <- 0\n",
    "  coverage  <- 0\n",
    "  cs_fdr    <- 0\n",
    "  cs_recall <- 0\n",
    "\n",
    "  if (length(test.cs) > 0) {\n",
    "    cs_size  <- length(unlist(test.cs)) / length(test.cs)\n",
    "    coverage <- sum(sapply(test.cs, function(cs) any(causal %in% cs))) / length(test.cs)\n",
    "\n",
    "    TP_fdr <- sum(sapply(test.cs, function(cs) any(cs %in% causal)))\n",
    "    FP_fdr <- length(test.cs) - TP_fdr\n",
    "    cs_fdr <- if ((TP_fdr + FP_fdr) > 0) FP_fdr / (TP_fdr + FP_fdr) else NA\n",
    "\n",
    "    TP_recall <- sum(causal %in% unlist(test.cs))\n",
    "    FN_recall <- length(causal) - TP_recall\n",
    "    cs_recall <- TP_recall / (TP_recall + FN_recall)\n",
    "  }\n",
    "\n",
    "  return(list(\n",
    "    cs_size   = cs_size,\n",
    "    coverage  = coverage,\n",
    "    cs_fdr    = cs_fdr,\n",
    "    cs_recall = cs_recall\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Main function to aggregate metrics from all methods\n",
    "evaluate_method_performance <- function(susie_out, susie_ash_out, susie_inf_out, fineboost_out, causal, data, precomp = NULL) {\n",
    "  # data$X is used directly.\n",
    "  susie_metrics      <- calc_metrics(susie_out,      method = \"susie\",      X = data$X, causal = causal)\n",
    "  susie_ash_metrics  <- calc_metrics(susie_ash_out,  method = \"susie_ash\",  X = data$X, causal = causal)\n",
    "  susie_inf_metrics  <- calc_metrics(susie_inf_out,  method = \"susie_inf\",  X = data$X, causal = causal)\n",
    "  fineboost_metrics  <- calc_metrics(fineboost_out,  method = \"fineboost\",  X = data$X, causal = causal)\n",
    "\n",
    "  # Create a summary metrics table\n",
    "  metrics_table <- data.frame(\n",
    "    Model     = c(\"SuSiE\", \"SuSiE.ash (Marginal)\", \"SuSiE-inf\", \"Fineboost\"),\n",
    "    CS_Size   = c(susie_metrics$cs_size,\n",
    "                  susie_ash_metrics$cs_size,\n",
    "                  susie_inf_metrics$cs_size,\n",
    "                  fineboost_metrics$cs_size),\n",
    "    Coverage  = c(susie_metrics$coverage,\n",
    "                  susie_ash_metrics$coverage,\n",
    "                  susie_inf_metrics$coverage,\n",
    "                  fineboost_metrics$coverage),\n",
    "    CS_FDR    = c(susie_metrics$cs_fdr,\n",
    "                  susie_ash_metrics$cs_fdr,\n",
    "                  susie_inf_metrics$cs_fdr,\n",
    "                  fineboost_metrics$cs_fdr),\n",
    "    CS_Recall = c(susie_metrics$cs_recall,\n",
    "                  susie_ash_metrics$cs_recall,\n",
    "                  susie_inf_metrics$cs_recall,\n",
    "                  fineboost_metrics$cs_recall)\n",
    "  )\n",
    "\n",
    "  return(list(metrics = metrics_table))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Simulation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Sparse Simulation Script\n",
    "# ================================\n",
    "\n",
    "# Load required libraries\n",
    "library(susieR)\n",
    "library(dplyr)\n",
    "library(magrittr)\n",
    "\n",
    "# Load Fineboost source files\n",
    "for (file in list.files(\"fineboost\", pattern = \"\\\\.R$\", full.names = TRUE)) {\n",
    "  source(file)\n",
    "}\n",
    "\n",
    "# Source helper functions from the helper_functions folder\n",
    "source(\"helper_functions/sparse_data_generation.R\")\n",
    "source(\"helper_functions/run_methods.R\")\n",
    "source(\"helper_functions/evaluate_method_performance.R\")\n",
    "\n",
    "##### STILL NEED simxQTL and susieash #####\n",
    "\n",
    "# Define the simulation function\n",
    "simulation <- function(num_simulations = NULL,\n",
    "                       h2_total        = NULL,\n",
    "                       K               = NULL,\n",
    "                       L               = NULL,\n",
    "                       null_max        = NULL,\n",
    "                       ld_mode         = NULL,\n",
    "                       K.length        = NULL,\n",
    "                       upper_bound     = NULL,\n",
    "                       LD_blocks_dir   = \"LD_blocks_precomputed\") {\n",
    "\n",
    "  # Set Default Values if parameters are missing\n",
    "  if (is.null(num_simulations)) num_simulations <- 2\n",
    "  if (is.null(h2_total))        h2_total        <- 0.3\n",
    "  if (is.null(K))               K               <- 5\n",
    "  if (is.null(L))               L               <- 10\n",
    "  if (is.null(null_max))        null_max        <- 0.02\n",
    "  if (is.null(ld_mode))         ld_mode         <- \"random\"\n",
    "  if (is.null(K.length))        K.length        <- 20\n",
    "  if (is.null(upper_bound))     upper_bound     <- 2\n",
    "\n",
    "  # Parse Command-Line Arguments (if any)\n",
    "  for (arg in commandArgs(trailingOnly = TRUE)) {\n",
    "    eval(parse(text = arg))\n",
    "  }\n",
    "\n",
    "  # List available LD block files and check count\n",
    "  ld_block_files <- list.files(path = LD_blocks_dir, pattern = \"\\\\.rds$\", full.names = TRUE)\n",
    "  if (length(ld_block_files) < num_simulations) {\n",
    "    stop(\"Not enough LD block files.\")\n",
    "  }\n",
    "  ld_block_files <- ld_block_files[1:num_simulations]\n",
    "\n",
    "  # Container for simulation metrics\n",
    "  all_metrics <- vector(\"list\", num_simulations)\n",
    "\n",
    "  # Loop over simulation replicates\n",
    "  for (i in seq_len(num_simulations)) {\n",
    "    cat(\"Running simulation\", i, \"of\", num_simulations, \"\\n\")\n",
    "\n",
    "    # Load precomputed LD block data\n",
    "    ld_block <- readRDS(ld_block_files[i])\n",
    "\n",
    "    # Store precomputed matrices (these can be large)\n",
    "    precomp <- list(\n",
    "      XtX  = ld_block$XtX,\n",
    "      LD   = ld_block$LD,\n",
    "      V    = ld_block$V,\n",
    "      Dsq  = ld_block$Dsq,\n",
    "      VtXt = ld_block$VtXt\n",
    "    )\n",
    "\n",
    "    # Generate simulation data with seed equal to the replicate index\n",
    "    data <- generate_sparse_eqtl_data(\n",
    "      X         = ld_block$X,\n",
    "      K         = K,\n",
    "      h2        = h2_total,\n",
    "      ld_mode   = ld_mode,\n",
    "      ld_matrix = ld_block$LD,\n",
    "      seed      = i\n",
    "    )\n",
    "\n",
    "    # Run methods via the wrapper functions\n",
    "    susie_out      <- run_susie(data, L, intercept = TRUE, standardize = FALSE)\n",
    "    susie_ash_out  <- run_susie_ash(data, precomp, L, K.length = K.length, upper_bound = upper_bound,\n",
    "                                    intercept = TRUE, standardize = FALSE)\n",
    "    susie_inf_out  <- run_susie_inf(data, precomp, L, intercept = TRUE, standardize = FALSE)\n",
    "    fineboost_out  <- run_fineboost(data, null_max, intercept = TRUE, standardize = FALSE)\n",
    "\n",
    "    # Evaluate metrics from all methods using the evaluation function\n",
    "    metrics <- evaluate_method_performance(\n",
    "      susie_out     = susie_out,\n",
    "      susie_ash_out = susie_ash_out,\n",
    "      susie_inf_out = susie_inf_out,\n",
    "      fineboost_out = fineboost_out,\n",
    "      causal        = data$causal_indices,\n",
    "      data          = data\n",
    "    )\n",
    "\n",
    "    # Save the metrics, data, and fine-mapping outputs\n",
    "    all_metrics[[i]] <- metrics\n",
    "\n",
    "    # Remove large objects no longer needed to free memory\n",
    "    rm(ld_block, precomp, susie_out, susie_ash_out, susie_inf_out, fineboost_out, data)\n",
    "    gc()\n",
    "  }\n",
    "\n",
    "  # Compile all results into a list including simulation parameters\n",
    "  simulation_results <- list(\n",
    "    all_metrics = all_metrics,\n",
    "    parameters  = list(\n",
    "      num_simulations = num_simulations,\n",
    "      h2_total        = h2_total,\n",
    "      K               = K,\n",
    "      L               = L,\n",
    "      null_max        = null_max,\n",
    "      ld_mode         = ld_mode,\n",
    "      K.length        = K.length,\n",
    "      upper_bound     = upper_bound,\n",
    "      LD_blocks_dir   = LD_blocks_dir\n",
    "    )\n",
    "  )\n",
    "\n",
    "  # Save Simulation Results as RDS File\n",
    "  output_dir <- \"/home/apm2217/output\"\n",
    "  file_name <- paste0(\"numIter\", num_simulations,\n",
    "                      \"_h2total\", h2_total,\n",
    "                      \"_K\", K,\n",
    "                      \"_L\", L,\n",
    "                      \"_nullMax\", null_max,\n",
    "                      \"_ldMode\", ld_mode,\n",
    "                      \"_Klength\", K.length,\n",
    "                      \"_upperBound\", upper_bound)\n",
    "\n",
    "  saveRDS(simulation_results, file.path(output_dir, paste0(file_name, \".rds\")))\n",
    "\n",
    "  # Return all results\n",
    "  return(simulation_results)\n",
    "}\n",
    "\n",
    "# Run the simulation and save the results\n",
    "results <- simulation(\n",
    "  num_simulations = NULL,\n",
    "  h2_total        = NULL,\n",
    "  K               = NULL,\n",
    "  L               = NULL,\n",
    "  null_max        = NULL,\n",
    "  ld_mode         = NULL,\n",
    "  LD_blocks_dir   = \"LD_blocks_precomputed\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
