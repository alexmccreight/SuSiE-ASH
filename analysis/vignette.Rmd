---
title: "Vignette"
output:
  html_document:
    toc: true
    toc_depth: 2      
    toc_float: true
date: "2025-02-14"
---

```{r, include = F}
# Libraries
library(tidyverse)
library(patchwork)
library(corrplot)
devtools::load_all('/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/submodules/susieR')
devtools::load_all('/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/new-rcpp/mr.ash.alpha')
source("/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/code/susie_versions/susie_inf.R")
source("/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/code/susie_versions/SuSiE_Ash_Marginal.R")
devtools::load_all('/Users/alexmccreight/Columbia/Research/simxQTL')

# Data
X20 <- readRDS("/Users/alexmccreight/Columbia/data/X20")
precomputed_matrices <- readRDS("/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/vignettes/precomputed_matrices.rds")

# Helper Functions
calibration_plot <- function(fit_list, pip_col, method_name, causal_indices_list) {
  
  # Combine PIP and truth information across all replicates.
  # For each replicate, create a truth vector of the same length as the PIP vector,
  # with 1 indicating a causal SNP (i.e. index is in causal_indices_list[[i]])
  all_data <- do.call(rbind, lapply(seq_along(fit_list), function(i) {
    pip_vals <- fit_list[[i]][[pip_col]]
    n <- length(pip_vals)
    # Create truth vector: 1 if index is causal, 0 otherwise.
    truth <- as.integer(seq_len(n) %in% causal_indices_list[[i]])
    data.frame(pip = pip_vals, truth = truth)
  }))
  
  # Bin the PIP values into 20 equally spaced bins from 0 to 1.
  all_data <- all_data %>%
    mutate(bin = cut(pip, breaks = seq(0, 1, length.out = 11), include.lowest = TRUE))
  
  # Summarize each bin: compute mean predicted PIP, observed frequency, and count.
  bin_summary <- all_data %>%
    group_by(bin) %>%
    summarise(
      mean_pip = mean(pip),
      obs_freq = mean(truth),
      n = n(),
      .groups = "drop"
    ) %>%
    # Calculate standard error (SE) and ± 2 SE error bars.
    mutate(
      se = sqrt(obs_freq * (1 - obs_freq) / n),
      lower = obs_freq - 2 * se,
      upper = obs_freq + 2 * se
    )
  
  # Create the calibration plot.
  p <- ggplot(bin_summary, aes(x = mean_pip, y = obs_freq)) +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.02) +
    geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dotted") +
    labs(x = "Mean PIP", y = "Observed Frequency", title = method_name) +
    theme_minimal() + ylim(0,1.25)
  
  return(p)
}

generate_eqtl_data <- function(X,
                               h2_total = 0.3,            # Total heritability. h2
                               prop_h2_sparse = 0.65,     # Proportion of h2_total explained by sparse effects (including sentinel).
                               prop_h2_oligogenic = 0.20, # Proportion of h2_total explained by oligogenic effects
                               prop_h2_infinitesimal = 0.15, # Proportion of h2_total explained by infinitesimal effects
                               prop_h2_sentinel = 0.7,    # Proportion of h2_sparse explained by sentinel SNP. h2_s
                               n_oligogenic = 20,
                               mixture_props = c(0.6, 0.4), # Adjusted mixture proportions
                               mixture_sds = c(0.0025, 0.005), # Standard deviations for mixture components
                               seed = NULL) {
  if (!is.null(seed)) set.seed(seed)

  ori.X <- X
  X <- scale(X)

  n_samples <- nrow(X)
  n_features <- ncol(X)

  # Calculate effect sizes for each component
  h2_sparse <- h2_total * prop_h2_sparse
  h2_sentinel <- h2_sparse * prop_h2_sentinel
  h2_other_sparse <- h2_sparse - h2_sentinel
  h2_oligogenic <- h2_total * prop_h2_oligogenic
  h2_infinitesimal <- h2_total * prop_h2_infinitesimal

  # Generate effect sizes
  beta <- rep(0, n_features)

  # Sentinel SNP effect (largest effect among sparse effects)
  sentinel_index <- sample(1:n_features, 1)
  beta[sentinel_index] <- rnorm(1, 0, sqrt(h2_sentinel))

  # Other sparse effects (large and mappable)
  n_other_sparse <- 2
  other_sparse_indices <- sample(setdiff(1:n_features, sentinel_index), n_other_sparse)
  if (n_other_sparse > 0) {
    # Distribute h2_other_sparse equally among other sparse SNPs
    beta[other_sparse_indices] <- rnorm(n_other_sparse, 0, sqrt(h2_other_sparse / n_other_sparse))
    # Ensure the sentinel SNP has the largest effect size
    max_other_sparse_effect <- max(abs(beta[other_sparse_indices]))
    if (abs(beta[sentinel_index]) <= max_other_sparse_effect) {
      beta[sentinel_index] <- sign(beta[sentinel_index]) * (max_other_sparse_effect + 0.01)
    }
  }

  # Combined sparse effects
  sparse_indices <- c(sentinel_index, other_sparse_indices)
  sparse_effects <- X[, sparse_indices] %*% beta[sparse_indices]

  # Scale sparse effects to achieve desired heritability
  scaling_factor_sparse <- sqrt(h2_sparse / var(sparse_effects))
  beta[sparse_indices] <- beta[sparse_indices] * as.vector(scaling_factor_sparse)

  # Ensure the sentinel SNP has the largest effect
  max_other_sparse_effect <- max(abs(beta[other_sparse_indices]))
  if (abs(beta[sentinel_index]) <= max_other_sparse_effect) {
    beta[sentinel_index] <- sign(beta[sentinel_index]) * (max_other_sparse_effect + 0.01)
  }

  # Oligogenic effects (adjust mixture proportions and sds)
  non_sparse_indices <- setdiff(1:n_features, c(sentinel_index, other_sparse_indices))
  n_oligogenic <- min(n_oligogenic, length(non_sparse_indices))
  oligogenic_indices <- sample(non_sparse_indices, n_oligogenic, replace = FALSE)

  mixture_assignments <- sample(1:length(mixture_props), length(oligogenic_indices), replace = TRUE, prob = mixture_props)
  beta[oligogenic_indices] <- rnorm(length(oligogenic_indices), 0, mixture_sds[mixture_assignments])

  # Scale oligogenic effects to achieve desired heritability
  oligogenic_effects <- X[, oligogenic_indices] %*% beta[oligogenic_indices]
  scaling_factor <- sqrt(h2_oligogenic / var(oligogenic_effects))
  beta[oligogenic_indices] <- beta[oligogenic_indices] * as.vector(scaling_factor)

  # Infinitesimal effects (small effects on remaining SNPs)
  infinitesimal_indices <- setdiff(non_sparse_indices, oligogenic_indices)
  infinitesimal_effects <- rep(0, n_features)
  if (length(infinitesimal_indices) > 0) {
    infinitesimal_effects[infinitesimal_indices] <- rnorm(length(infinitesimal_indices), 0, sqrt(h2_infinitesimal / length(infinitesimal_indices)))
  }
  beta <- beta + as.vector(infinitesimal_effects)

  # Generate y
  y <- X %*% beta

  # Add noise to achieve desired total heritability
  var_y <- var(as.vector(y))
  var_epsilon <- var_y * (1 - h2_total) / h2_total
  epsilon <- rnorm(n_samples, 0, sqrt(var_epsilon))
  y <- y + epsilon

  # Calculate actual heritabilities
  var_y_total <- var(as.vector(y))
  h2_sentinel_actual <- var(X[, sentinel_index] * beta[sentinel_index]) / var_y_total

  # Sparse effects heritability
  sparse_indices <- c(sentinel_index, other_sparse_indices)
  h2_sparse_actual <- var(X[, sparse_indices] %*% beta[sparse_indices]) / var_y_total

  # Oligogenic effects heritability
  h2_oligogenic_actual <- var(X[, oligogenic_indices] %*% beta[oligogenic_indices]) / var_y_total

  # Infinitesimal effects heritability
  h2_infinitesimal_actual <- var(X %*% infinitesimal_effects) / var_y_total

  h2_total_actual <- var(as.vector(X %*% beta)) / var_y_total

  ori.y <- y
  y <- scale(y, center = TRUE, scale = FALSE)

  # Create a full-length mixture_assignments vector
  mixture_assignments_full <- rep(NA, n_features)
  mixture_assignments_full[oligogenic_indices] <- mixture_assignments

  return(list(
    ori.X = ori.X,
    X = X,
    ori.y = ori.y,
    y = y,
    beta = beta,
    h2_total = h2_total_actual,
    h2_sparse = h2_sparse_actual,
    h2_sentinel = h2_sentinel_actual,
    h2_oligogenic = h2_oligogenic_actual,
    h2_infinitesimal = h2_infinitesimal_actual,
    sentinel_index = sentinel_index,
    other_sparse_indices = other_sparse_indices,
    oligogenic_indices = oligogenic_indices,
    infinitesimal_indices = infinitesimal_indices,
    mixture_assignments = mixture_assignments_full,
    var_epsilon = var_epsilon,
    sparse_indices = sparse_indices
  ))
}

# Function to Identify Causal SNPs Based on PVE Threshold
is_causal <- function(eqtl_data, pve_threshold) {
  # Get the beta vector and residual variance for this simulation
  beta <- eqtl_data$beta
  var_epsilon <- eqtl_data$var_epsilon

  # Compute variance explained by each SNP (since Var(X_j) = 1)
  variance_explained <- beta^2

  # Compute total genetic variance
  var_g <- sum(variance_explained)

  # Compute total variance (genetic variance + residual variance)
  total_variance <- var_g + var_epsilon

  # Compute PVE for each SNP
  proportion_var_explained <- variance_explained / total_variance

  # Define causal SNPs based on the current PVE threshold
  causal_SNPs <- which(proportion_var_explained > pve_threshold)
  return(causal = causal_SNPs)
}

calibration_plot_methods <- function(res) {

  # Number of replicates (assumed to be 100)
  n_reps <- length(res)
  
  # Pre-allocate lists to store the PIP vectors for each method and the causal indices.
  susie_pip         <- vector("list", n_reps)
  susie_refined_pip <- vector("list", n_reps)
  susie_inf_pip     <- vector("list", n_reps)
  susie_ash_pip     <- vector("list", n_reps)
  causal_list       <- vector("list", n_reps)
  
  # Loop over replicates and extract the PIP vectors and causal indices.
  for (i in seq_len(n_reps)) {
    susie_pip[[i]]         <- res[[i]]$method_results$susie$fit$pip
    susie_refined_pip[[i]] <- res[[i]]$method_results$susie_refined$fit$pip
    susie_inf_pip[[i]]     <- res[[i]]$method_results$susie_inf$fit$marginal_PIP
    susie_ash_pip[[i]]     <- res[[i]]$method_results$susie_ash$fit$PIP2
    causal_list[[i]]       <- res[[i]]$sim_data$causal_indices
  }
  
  # Helper function: Given a list of PIP vectors and a list of causal indices,
  # create a calibration plot.
  calibration_plot_vector <- function(pip_list, method_name, causal_indices_list) {
    # Combine data across replicates.
    all_data <- do.call(rbind, lapply(seq_along(pip_list), function(i) {
      pip_vals <- pip_list[[i]]
      n <- length(pip_vals)
      # Create truth vector: 1 if the index is causal, 0 otherwise.
      truth <- as.integer(seq_len(n) %in% causal_indices_list[[i]])
      data.frame(pip = pip_vals, truth = truth)
    }))
    
    # Bin the PIP values into 10 bins (0 to 1).
    all_data <- all_data %>%
      mutate(bin = cut(pip, breaks = seq(0, 1, length.out = 11), include.lowest = TRUE))
    
    # Summarize each bin.
    bin_summary <- all_data %>%
      group_by(bin) %>%
      summarise(
        mean_pip = mean(pip),
        obs_freq = mean(truth),
        n = n(),
        .groups = "drop"
      ) %>%
      mutate(
        se = sqrt(obs_freq * (1 - obs_freq) / n),
        lower = obs_freq - 2 * se,
        upper = obs_freq + 2 * se
      )
    
    # Create and return the ggplot calibration plot.
    p <- ggplot(bin_summary, aes(x = mean_pip, y = obs_freq)) +
      geom_point(size = 2) +
      geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.02) +
      geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dotted") +
      labs(x = "Mean PIP", y = "Observed Frequency", title = method_name) +
      theme_minimal() + ylim(0, 1.25)
    
    return(p)
  }
  
  # Create calibration plots for each method.
  p_susie         <- calibration_plot_vector(susie_pip, "Susie", causal_list)
  p_susie_refined <- calibration_plot_vector(susie_refined_pip, "Susie Refined", causal_list)
  p_susie_inf     <- calibration_plot_vector(susie_inf_pip, "Susie Inf", causal_list)
  p_susie_ash     <- calibration_plot_vector(susie_ash_pip, "Susie Ash", causal_list)
  
  # Return the plots as a list.
  return(list(
    susie = p_susie,
    susie_refined = p_susie_refined,
    susie_inf = p_susie_inf,
    susie_ash = p_susie_ash
  ))
}

get_valid_causal <- function(G, ncausal, ld_threshold = 0.25, max_attempts = 100) {
  # G: genotype matrix (n x p)
  # ncausal: number of causal variants to select
  # ld_threshold: maximum allowed pairwise r^2 between causal variants
  # max_attempts: maximum attempts to find a valid set
  snp_indices <- seq_len(ncol(G))
  for (attempt in 1:max_attempts) {
    causal_indices <- sort(sample(snp_indices, ncausal))
    # Compute correlation among the selected SNPs
    corr_mat <- cor(G[, causal_indices])
    # Zero out diagonal and lower triangle to check only off-diagonals
    corr_mat[lower.tri(corr_mat, diag = TRUE)] <- 0
    # If maximum r^2 is below threshold, return these indices
    if (max(abs(corr_mat)) < ld_threshold) {
      return(causal_indices)
    }
  }
  stop("Could not find a set of causal variants with LD (r^2) below ",
       ld_threshold, " after ", max_attempts, " attempts.")
}

generate_sparse_eqtl_data <- function(X,
                                      K = 10,      # Number of effect SNPs
                                      h2 = 0.3,    # Variance explained
                                      seed = NULL) {
  if (!is.null(seed)) set.seed(seed)

  n_samples <- nrow(X)
  n_features <- ncol(X)

  # Initialize beta (effect sizes) to zero
  beta <- rep(0, n_features)

  # (a) Sample causal SNP indices
  causal_indices <- sample(1:n_features, K, replace = FALSE)

  # (b) Assign N(0, 0.6^2) effects to causal SNPs
  beta[causal_indices] <- rnorm(K, mean = 0, sd = 0.6)

  # Compute genetic effects
  genetic_effect <- X %*% beta

  # (c) Solve for σ²
  var_g <- var(genetic_effect)  # Variance from genetic effects
  var_e <- var_g * (1 - h2) / h2  # Residual variance

  # (d) Generate phenotype y ~ N(Xβ, σ²)
  y <- genetic_effect + rnorm(n_samples, mean = 0, sd = sqrt(var_e))

  # Return results
  return(list(
    X = X,
    y = y,
    beta = beta,
    causal_indices = causal_indices,
    var_epsilon = var_e,
    h2_input = h2,
    h2_estimated = var_g / (var_g + var_e)
  ))
}

plot_susie_fit <- function(fit, data, model = c("original", "inf", "ash"),
                             threshold = 0.05, set_par = TRUE) {
  model <- match.arg(model)
  
  # Extract the appropriate matrix.
  # For "original": fit$alpha is L x p.
  # For "inf" and "ash": fit$PIP is p x L, so we transpose.
  if (model == "original") {
    mat <- fit$alpha
    title_model <- "SuSiE"
  } else if (model %in% c("inf", "ash")) {
    mat <- t(fit$PIP)
    title_model <- if (model == "inf") "SuSiE-inf" else "SuSiE-ash"
  } else {
    stop("Invalid model type. Please choose 'original', 'inf', or 'ash'.")
  }
  
  # Compute the maximum PIP for each group (row) and filter groups by threshold.
  max_alpha <- apply(mat, 1, max)
  keep <- max_alpha >= threshold
  alpha_filtered <- mat[keep, , drop = FALSE]
  
  if (!requireNamespace("RColorBrewer", quietly = TRUE)) {
    stop("RColorBrewer package is required but not installed.")
  }
  library(RColorBrewer)
  
  num_groups <- nrow(alpha_filtered)
  if (num_groups <= 8) {
    group_colors <- brewer.pal(num_groups, "Set1")
  } else {
    group_colors <- colorRampPalette(brewer.pal(9, "Set1"))(num_groups)
  }
  
  # Optionally set plotting parameters (margins, etc.).
  if (set_par) {
    par(mar = c(5, 4, 4, 8), xpd = TRUE)
  }
  
  # Create the barplot and store the bar midpoints.
  bp <- barplot(alpha_filtered,
                beside = TRUE,
                col = group_colors,
                border = NA,
                names.arg = 1:ncol(alpha_filtered),
                xlab = "Variable index (p)",
                ylab = "Posterior Inclusion Probability (alpha)",
                main = paste(title_model, "- Filtered Posterior Inclusion Probabilities by Group")
  )
  
  # Compute the x positions (centers) for each cluster of bars.
  cluster_x <- colMeans(bp)
  y_marker <- -0.02
  
  # Compute dot sizes based on absolute effect sizes.
  dot_cex <- abs(data$beta[data$causal_indices])
  if (max(dot_cex) > 0) {
    dot_cex <- dot_cex / max(dot_cex) * 1.25
  } else {
    dot_cex <- rep(1, length(dot_cex))
  }
  
  # Determine the credible set variants based on the model.
  # For the original model, assume fit$sets$cs contains the credible sets.
  # For the inf/ash models, use fit$sets[[1]].
  if (model == "original") {
    cs_variants <- unlist(fit$sets$cs)
  } else {
    cs_variants <- unlist(fit$sets)
  }
  
  # For each causal variant, if it is in the credible set, use green; else red.
  causal_indices <- data$causal_indices
  dot_colors <- ifelse(causal_indices %in% cs_variants, "green", "red")
  
  # Add the causal index points with the appropriate colors and scaled sizes.
  points(cluster_x[causal_indices],
         rep(y_marker, length(causal_indices)),
         pch = 19,
         col = dot_colors,
         cex = dot_cex)
  
  # Add a legend for the groups.
  legend("topright",
         inset = c(-0.25, 0),
         legend = paste("Group", which(keep)),
         fill = group_colors,
         cex  = 0.8,
         ncol = 1)
}


reproduce_simulation_data <- function(X, seed_val, ncausal = 10, h2 = 0.3, 
                                        ld_threshold = 0.25, max_attempts = 10000) {
  # This function sets the seed and then calls generate_sparse_eqtl_data
  # to produce the same simulation data instance reproducibly.
  data_instance <- generate_sparse_eqtl_data(X, 
                                             K = ncausal, 
                                             h2 = h2, 
                                             seed = seed_val, 
                                             ld_threshold = ld_threshold, 
                                             max_attempts = max_attempts)
  return(data_instance)
}

generate_sparse_eqtl_data <- function(X,
                                      K = 10,      # Number of effect SNPs
                                      h2 = 0.3,    # Variance explained
                                      seed = NULL,
                                      ld_threshold = 0.25,
                                      max_attempts = 100) {
  if (!is.null(seed)) set.seed(seed)

  n_samples <- nrow(X)
  n_features <- ncol(X)

  # Initialize beta (effect sizes) to zero
  beta <- rep(0, n_features)

  # Select causal indices that meet the low-LD condition
  causal_indices <- get_valid_causal(G = X, ncausal = K,
                                     ld_threshold = ld_threshold,
                                     max_attempts = max_attempts)

  # Assign effects ~ N(0, 0.6^2) to the causal SNPs
  beta[causal_indices] <- rnorm(K, mean = 0, sd = 0.6)

  # Compute genetic effects
  genetic_effect <- X %*% beta

  # Calculate variance components for the desired heritability
  var_g <- var(genetic_effect)           # Variance due to genetic effects
  var_e <- var_g * (1 - h2) / h2           # Residual variance

  # Generate phenotype: y ~ N(Xβ, σ²)
  y <- genetic_effect + rnorm(n_samples, mean = 0, sd = sqrt(var_e))

  # Return the generated data and simulation parameters
  return(list(
    X = X,
    y = y,
    beta = beta,
    causal_indices = causal_indices,
    var_epsilon = var_e,
    h2_input = h2,
    h2_estimated = var_g / (var_g + var_e)
  ))
}

calc_metrics <- function(mod, X = X, y = y, causal = causal) {
    #### Initialize values ####
    test.cs <- susie_get_cs(mod, X = X, coverage = 0.95)$cs
    coverage <- 0
    cs_fdr <- 0
    cs_recall <- 0
    cs_size <- 0

    if (length(test.cs) > 0) {
      # Calculate Average CS Size
      cs_size <- length(unlist(test.cs)) / length(test.cs)

      # Calculate Coverage (proportion of credible sets with a causal effect)
      coverage <- (lapply(1:length(test.cs), function(cs.l) { ifelse(sum(causal %in% test.cs[[cs.l]]) != 0, TRUE, FALSE) }) %>% unlist() %>% sum()) / (length(test.cs))

      # CS Based FDR
      TP_fdr <- lapply(1:length(test.cs), function(cs.l) { ifelse(sum(test.cs[[cs.l]] %in% causal) != 0, TRUE, FALSE) }) %>% unlist() %>% sum()
      FP_fdr <- length(test.cs) - TP_fdr
      cs_fdr <- ifelse((TP_fdr + FP_fdr) > 0, FP_fdr / (TP_fdr + FP_fdr), NA)

      # CS Based Recall
      TP_recall <- sum(causal %in% unlist(test.cs))
      FN_recall <- length(causal) - TP_recall
      cs_recall <- TP_recall / (TP_recall + FN_recall)
    }

    #### Calculate RMSE ####
    RMSE_y <- sqrt(mean((y - mod$fitted)^2))

    #### Store Results ####
    return(list(
      RMSE_y = RMSE_y,
      cs_size = cs_size,
      coverage = coverage,
      cs_fdr = cs_fdr,
      cs_recall = cs_recall
    ))
}

calc_metrics_inf <- function(mod, X = X, y = y, causal = causal) {
    #### Initialize values ####
    test.cs <- mod$sets
    coverage <- 0
    cs_fdr <- 0
    cs_recall <- 0
    cs_size <- 0

    if (length(test.cs) > 0) {
      # Calculate Average CS Size
      cs_size <- length(unlist(test.cs)) / length(test.cs)

      # Calculate Coverage (proportion of credible sets with a causal effect)
      coverage <- (lapply(1:length(test.cs), function(cs.l) { ifelse(sum(causal %in% test.cs[[cs.l]]) != 0, TRUE, FALSE) }) %>% unlist() %>% sum()) / (length(test.cs))

      # CS Based FDR
      TP_fdr <- lapply(1:length(test.cs), function(cs.l) { ifelse(sum(test.cs[[cs.l]] %in% causal) != 0, TRUE, FALSE) }) %>% unlist() %>% sum()
      FP_fdr <- length(test.cs) - TP_fdr
      cs_fdr <- ifelse((TP_fdr + FP_fdr) > 0, FP_fdr / (TP_fdr + FP_fdr), NA)

      # CS Based Recall
      TP_recall <- sum(causal %in% unlist(test.cs))
      FN_recall <- length(causal) - TP_recall
      cs_recall <- TP_recall / (TP_recall + FN_recall)
    }

    #### Calculate RMSE ####
    RMSE_y <- sqrt(mean((y - mod$fitted)^2))

    #### Store Results ####
    return(list(
      RMSE_y = RMSE_y,
      cs_size = cs_size,
      coverage = coverage,
      cs_fdr = cs_fdr,
      cs_recall = cs_recall
    ))
  }
```

This vignette demonstrates investigates the contribution of the ash component in a replicate of the oligogenic setting, compares SuSiE-ash's overall performance to SuSiE and SuSiE-inf across three sparse scenarios of varying LD structure, and delves into an iteration analysis pinpointing where false positives are introduced. For the oligogenic scenario, we set L = 10, heritability = 0.3 and use a n = 5000, p = 6300 genotype matrix. For all sparse scenarios, we sample 10 causal variants, set `L=20`, heritability = 0.3, and use a n = 540, p = 950 genotype matrix. 

**I will start by pointing out areas of concern I have noticed in our results**

1. mr.ash coefficient values and their variance are small, $\theta$ and Var($\theta_j$) are very in both sparse and oligogenic settings (even compared to susie-inf's infinitesimal component, $\alpha$, values).

2. Each time we run the mr.ash algorithm within our susie-ash (Marginal) code, it usually converges on the first outer-loop iteration, but never goes above three iterations.

# Examples of Issues in Oligogenic Setting

## Metrics for this single replicate

```{r, echo = F}
# Create a data frame with the specified models and metrics
df <- data.frame(
  Model = c("SuSiE-ash Marginal", "SuSiE", "SuSiE-inf"),
  CS_FDR = c(0.25, 0.3333333, 0.0000000),
  CS_Recall = c(0.8571429, 0.8571429, 0.7142857),
  CS_Size = c(15, 15.555556, 2)
)

# Round numeric columns to 3 decimals
df$CS_FDR   <- round(df$CS_FDR, 3)
df$CS_Recall <- round(df$CS_Recall, 3)
df$CS_Size  <- round(df$CS_Size, 3)

# Display the data frame
print(df)

```


## First Replicate LD of Causal Variants (and a window around them)

```{r, echo = F}
data <- generate_eqtl_data(X = X20, mixture_props = c(0.75, 0.25), seed = 5)
data$causal <- is_causal(data, pve_threshold = 0.005)

LD_mat <- precomputed_matrices$LD
colnames(LD_mat) <- 1:ncol(LD_mat)
rownames(LD_mat) <- 1:nrow(LD_mat)
#LD_mat[data$causal,data$causal]


# Define causal indices
causal_indices <- data$causal

# Extract a window (with boundary checks) for each causal index
window_indices <- sort(unique(unlist(lapply(causal_indices, function(i) {
  start <- max(1, i - 100)
  end   <- min(nrow(LD_mat), i + 100)
  seq(from = start, to = end)
}))))

# Extract the submatrix corresponding to the union of all these windows
subLD <- LD_mat[window_indices, window_indices]

# Plot a single heatmap for the submatrix
heatmap(abs(subLD),
        Rowv = NA,
        Colv = NA,
        symm = TRUE,
        col = colorRampPalette(c("white", "red"))(20),
        main = "LD abs(r) for Causal Variants +/- 100 variant window")

seed5 <- readRDS("/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/vignettes/seed5_oligo.rds")
seed5_inf <- readRDS("/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/overleaf_graphics/marginal_omnigenic_results_experiments_rerun/numIter100_h2total0.3_h2sentinel0.7_L10_numOligogenic20_pvethreshold0.005_mixturesmall0.75_K10_upperBound3.rds")

# susie_ash_marginal_output <- susie_ash_RE_Marg(
#     X       = scale(data$ori.X),
#     y       = scale(data$ori.y),
#     L       = 10,
#     verbose = FALSE,
#     coverage= 0.95,
#     XtX     = precomputed_matrices$XtX,
#     LD      = precomputed_matrices$LD,
#     V       = precomputed_matrices$V,
#     Dsq     = precomputed_matrices$Dsq,
#     VtXt    = precomputed_matrices$VtXt,
#     update_ash_sigma = F,
#     K.length = 20,
#     upper_bound = 3
#   )
```

Causal variants in this setting are nearly independent. The highest correlation between two causal variants is r = 0.21.


```{r, echo = F}
cat("SuSiE-ash mixture proportions (pi):\n")
for(i in seq_along(seed5$pi)) {
  cat(sprintf("Component %2d: %0.8f\n", i, seed5$pi[i]))
}
```

Nearly all mixture proportions are zero besides the first, which corresponds to the null effects. This is a regular occurance in both oligogenic and sparse settings.

```{r, echo = F}
cat("\nSuSiE-ash Var(theta):", seed5$tausq)
cat("\nSuSiE-inf Var(alpha):", seed5_inf$all_susie_inf_outputs[[5]]$tausq)
```

The ash component variance is actually smaller than the infinitesimal component variance even though it is supposed to be capturing the oligogenic effects. I wonder if this is because the null weight, component 1 shown just above, has such a high proportion compared to everything else.

```{r, echo = F}
# cat("\nSuSiE-ash mean(abs(theta)):", mean(abs(seed5$theta)))
# cat("\nSuSiE-inf mean(abs(alpha)):", mean(abs(seed5_inf$all_susie_inf_outputs[[5]]$alpha)))
cat("\nSuSiE-ash max(abs(theta)):", max(abs(seed5$theta)))
cat("\nSuSiE-inf max(abs(alpha)):", max(abs(seed5_inf$all_susie_inf_outputs[[5]]$alpha)))
```

Additionally, the maximum absolute coefficient value from the ash component is incredibly small, essentially negligible. Again, I wonder if this is because the component 1 dominance shown above. 

```{r, echo = F}
# Create the data frame with the desired two columns
df <- data.frame(
  Method = c("Truth", "SuSiE", "SuSiE-ash", "SuSiE-inf"),
  ResidualVariance = c(
    data$var_epsilon,
    seed5_inf$all_susie_outputs[[5]]$sigma2,
    seed5$sigmasq,
    seed5_inf$all_susie_inf_outputs[[5]]$sigmasq
  )
)

# Print the resulting data frame
df$ResidualVariance <- round(df$ResidualVariance, 3)
print(df)

```

When looking at the residual variance estimates SuSiE over predicts the residual variance, meanwhile SuSiE-ash and Inf both under predict it.   

# Overall Performance in Sparse Setting. Metrics Averaged over 100 Replicates.

## Completely Independent Genotype Matrix

```{r, echo = F, message = F, warning = F}
res <- readRDS("/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/vignettes/independent_res.rds")

metrics_df <- do.call(rbind, lapply(res, function(res) {
  replicate <- res$replicate
  sapply(names(res$method_results), function(method) {
    data.frame(
      replicate = replicate,
      method = method,
      cs_fdr = res$method_results[[method]]$metrics$cs_fdr,
      cs_recall = res$method_results[[method]]$metrics$cs_recall
    )
  }, simplify = FALSE)
}) )

plots <- calibration_plot_methods(res)

metrics_df <- do.call(rbind, metrics_df)


metrics_df <- metrics_df %>%
  mutate(method = recode(method,
                         "susie"         = "SuSiE",
                         "susie_refined" = "SuSiE (w/ Refine)",
                         "susie_inf"     = "SuSiE-inf",
                         "susie_ash"     = "SuSiE-ash Marginal"))


metrics_df %>% group_by(method) %>% summarize(FDR = mean(cs_fdr),
                                              Power = mean(cs_recall))




(plots$susie + plots$susie_ash + plots$susie_inf)
```


```{r, include = F}
rm(metrics_df, res)
gc()
```

When we create an independent genotype matrix and run our SuSiE variants, we see they all perform nearly identically. None of the methods suffer from any false positives and they all capture roughly half of all causal variants. It is important to note that none of the methods look calibrated in this scenario. Specifically, they all seem to underestimating the true probability of a variant being causal

## Sparse Setting Real Genotype Matrix LD Structure (p = 930)

```{r, echo = F}
X_subset <- readRDS("/Users/alexmccreight/Downloads/X_subset")
scaled_X_full <- scale(X_subset)
n_samples <- nrow(scaled_X_full)
XtX <- t(scaled_X_full) %*% scaled_X_full
LD  <- XtX / n_samples
eig <- eigen(LD, symmetric = TRUE)
V   <- eig$vectors[, ncol(eig$vectors):1]
Dsq <- pmax(n_samples * sort(eig$values), 0)
VtXt <- t(V) %*% t(scaled_X_full)
LD_mat <- cor(X_subset)
colnames(LD_mat) <- 1:ncol(LD_mat)
rownames(LD_mat) <- 1:nrow(LD_mat)

heatmap(abs(LD_mat),
        Rowv = NA,
        Colv = NA,
        symm = TRUE,
        col = colorRampPalette(c("white", "red"))(20),
        main = "LD abs(r) for Genotype Matrix")
```

## Low LD among Causal variants (abs(r) < 0.25)

```{r, echo = F}
res <- readRDS("/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/vignettes/lowLD_res.rds")

# Average FDR for each method
avg_fdr_df <- data.frame(
  Method = c("Susie", "Susie-ash", "Susie-inf"),
  FDR    = c(mean(res$cs_fdr_susie), 
             mean(res$cs_fdr_susie_ash), 
             mean(res$cs_fdr_susie_inf))
)

# Average Recall for each method
avg_recall_df <- data.frame(
  Method = c("Susie", "Susie-ash", "Susie-inf"),
  Recall = c(mean(res$cs_recall_susie), 
             mean(res$cs_recall_susie_ash), 
             mean(res$cs_recall_susie_inf))
)

# FDR bar plot
p_fdr_bar <- ggplot(avg_fdr_df, aes(x = Method, y = FDR, fill = Method)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_hline(yintercept = 0.05, linetype = "dotted", color = "red") +
  labs(title = "Average FDR by Method", x = "Method", y = "Average FDR") +
  theme_minimal() +
  theme(legend.position = "none") + ylim(0,1)

# Recall bar plot
p_recall_bar <- ggplot(avg_recall_df, aes(x = Method, y = Recall, fill = Method)) +
  geom_bar(stat = "identity", width = 0.7) +
  labs(title = "Average Recall by Method", x = "Method", y = "Average Recall") +
  theme_minimal() +
  theme(legend.position = "none") + ylim(0,1)


# Calibration plot for Susie:
p_susie <- calibration_plot(
  fit_list = res$fit_susie, 
  pip_col = "pip", 
  method_name = "Susie", 
  causal_indices_list = res$causal_indices
)

# Calibration plot for Susie-ash:
p_susie_ash <- calibration_plot(
  fit_list = res$fit_susie_ash, 
  pip_col = "PIP2", 
  method_name = "Susie-ash", 
  causal_indices_list = res$causal_indices
)

# Calibration plot for Susie-inf:
p_susie_inf <- calibration_plot(
  fit_list = res$fit_susie_inf, 
  pip_col = "marginal_PIP", 
  method_name = "Susie-inf", 
  causal_indices_list = res$causal_indices
)


(p_fdr_bar + p_recall_bar) / (p_susie + p_susie_ash + p_susie_inf)
```

Even in this Low LD among causal variant scenario, we begin to see increased FDR in both SuSiE/SuSiE-ash. While it remains, controlled SuSiE-inf is clearly able to remain more conservative while maintaining competitive recall. As for the calibration, all three methods appear to work the same around the extremes (e.g. mean PIP = 0 , 1), however, in where things become less clear (e.g. mean PIP = 0.5), SuSiE-inf has better performance. At this mean PIP = 0.5, it looks like both SuSiE and especially SuSiE-ash are too anti-conservative (much below the red line).

```{r, include = F}
rm(res)
gc()
```

## Moderate LD among Causal variants (abs(r) < 0.50)

```{r, echo = F}
res <- readRDS("/Users/alexmccreight/Columbia/Research/SuSiE-ASH/SuSiE-ASH/vignettes/mediumLD_res.rds")

# Average FDR for each method
avg_fdr_df <- data.frame(
  Method = c("Susie", "Susie-ash", "Susie-inf"),
  FDR    = c(mean(res$cs_fdr_susie), 
             mean(res$cs_fdr_susie_ash), 
             mean(res$cs_fdr_susie_inf))
)

# Average Recall for each method
avg_recall_df <- data.frame(
  Method = c("Susie", "Susie-ash", "Susie-inf"),
  Recall = c(mean(res$cs_recall_susie), 
             mean(res$cs_recall_susie_ash), 
             mean(res$cs_recall_susie_inf))
)


# FDR bar plot
p_fdr_bar <- ggplot(avg_fdr_df, aes(x = Method, y = FDR, fill = Method)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_hline(yintercept = 0.05, linetype = "dotted", color = "red") +
  labs(title = "Average FDR by Method", x = "Method", y = "Average FDR") +
  theme_minimal() +
  theme(legend.position = "none") + ylim(0,1)

# Recall bar plot
p_recall_bar <- ggplot(avg_recall_df, aes(x = Method, y = Recall, fill = Method)) +
  geom_bar(stat = "identity", width = 0.7) +
  labs(title = "Average Recall by Method", x = "Method", y = "Average Recall") +
  theme_minimal() +
  theme(legend.position = "none") + ylim(0,1)

# Calibration plot for Susie
p_susie <- calibration_plot(
  fit_list = res$fit_susie, 
  pip_col = "pip", 
  method_name = "Susie", 
  causal_indices_list = res$causal_indices
)

# Calibration plot for Susie-ash
p_susie_ash <- calibration_plot(
  fit_list = res$fit_susie_ash, 
  pip_col = "PIP2", 
  method_name = "Susie-ash", 
  causal_indices_list = res$causal_indices
)

# Calibration plot for Susie-inf
p_susie_inf <- calibration_plot(
  fit_list = res$fit_susie_inf, 
  pip_col = "marginal_PIP", 
  method_name = "Susie-inf", 
  causal_indices_list = res$causal_indices
)

(p_fdr_bar + p_recall_bar) / (p_susie + p_susie_ash + p_susie_inf)

```

In the moderate LD among causal variant scenario, the increase in FDR in all SuSiE/SuSiE-ash is even more extreme, while SuSiE-inf remains controlled and still maintaining competitive recall. In terms of calibration plots, visually there is becoming less of a difference among the three methods

# Iteration Analysis of Sparse Setting with Low LD abs(r) < 0.25.

For the following iteration analysis, we will be examining how the alpha plots change across each iteration (determining whether this they begin to vary early on or later), also seeing if this could be remedied by a better initialization (i.e. using `refine = T`). For the plots, if a single alpha values within one of the effect groups, `L`, is greater than 0.05, than we will include that group into the legend (this is to stop including 20 different Ls). Additionally, causal variants are marked as dots on the bottom of the graph (red = not captured, green = captured) -- **these dots' size are proportional to their magnitude**.

## Scenario 1: SuSiE + SuSiE-ash pick up 4 total sets (2 true, 2 false), SuSiE-inf picks up no sets.

```{r, include = F}
data <- reproduce_simulation_data(X_subset, seed_val = 8) 
susie_fit <- susie(X = data$X, # 8 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T)

susie_inf_fit <- susie_inf(X = scale(data$X), # 7 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 22 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt)

susie_metrics <- calc_metrics(susie_fit, X = data$X, y = data$y, causal = data$causal_indices)
susie_inf_metrics <- calc_metrics_inf(susie_inf_fit, X = data$X, y = data$y, causal = data$causal_indices)
susie_ash_metrics <- calc_metrics_inf(susie_ash_fit, X = data$X, y = data$y, causal = data$causal_indices)

# Create a data frame with the desired metrics
df <- data.frame(
  Method = c("SuSiE", "SuSiE-inf", "SuSiE-ash"),
  FDR = c(0.5, 0, 0.5),
  Recall = c(0.2, 0, 0.2),
  CS_Size = c(15, 0, 14.5)
)
```


```{r, echo = F}
# Display the data frame
print(df)

```

```{r, include = F}
LD_mat <- cor(X_subset)
colnames(LD_mat) <- 1:ncol(LD_mat)
rownames(LD_mat) <- 1:nrow(LD_mat)

LD_mat[data$causal_indices, unlist(susie_ash_fit$sets)]
```


### Iteration 1

For the first iteration, all three methods pick up a single, false positive set. Every variant in this set is in moderate LD with both one of the largest variants by magnitude and another smaller causal variant (LD ~0.6 and ~0.4, respectively).

### Iteration 2

For the second iteration, both SuSiE and SuSiE-ash have 3 total CS (2 true, 1 false positive). Note this false positive is different from the one from the first iteration. The original false positive from iteration 1 was shrunk. SuSiE-inf capture has a single credible set containing a causal variant.

```{r, include = F}
susie_fit <- susie(X = data$X, # 8 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T,
      max_iter = 2)

susie_inf_fit <- susie_inf(X = scale(data$X), # 7 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           maxiter = 2)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 22 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt,
                           maxiter = 2)
```

```{r, echo = F, warning = F, message = F}
# For the original SuSiE model (with susie_fit$alpha as an L x p matrix):
plot_susie_fit(susie_fit, data, model = "original")

# For the SuSiE-inf model (with susie_inf_fit$PIP as a p x L matrix):
plot_susie_fit(susie_inf_fit, data, model = "inf")

# For the SuSiE-ash model (with susie_ash_fit$PIP as a p x L matrix):
plot_susie_fit(susie_ash_fit, data, model = "ash")
```

### Iteration 3

For the third iteration, SuSiE / SuSiE-ash both introduce an additional false positive cs of size 53 and 50, respectively and retain the original 3 from the previous iteration. All of these variants in the new CS are in moderately high LD (~ 0.65) with the same small causal variant from the first iteration. On the PIP graph this corresponds to Group 4 and they're in LD with causal variant ID = 741. SuSiE-inf no longer has any credible sets past this iteration. 

```{r, include = F}
susie_fit <- susie(X = data$X, # 8 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T,
      max_iter = 3)

susie_inf_fit <- susie_inf(X = scale(data$X), # 7 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           maxiter = 3)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 22 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt,
                           maxiter = 3)
```

```{r, echo = F, warning = F, message = F}
# For the original SuSiE model (with susie_fit$alpha as an L x p matrix):
plot_susie_fit(susie_fit, data, model = "original")

# For the SuSiE-inf model (with susie_inf_fit$PIP as a p x L matrix):
plot_susie_fit(susie_inf_fit, data, model = "inf")

# For the SuSiE-ash model (with susie_ash_fit$PIP as a p x L matrix):
plot_susie_fit(susie_ash_fit, data, model = "ash")
```

### Final Iteration

SuSiE converged after 8 iterations, SuSiE-inf after 7, and SuSiE-ash after 22. SuSiE and SuSiE-ash retained their 4 CS, although slightly reduced the sizes of them. SuSiE-inf not only didn't have a single CS, it's maximum PIP value (alpha value in SuSiE) was only 0.001. Thus, it was so uncertain it shrunk every effect to essentially null. 

```{r, include = F}
susie_fit <- susie(X = data$X, # 8 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T)

susie_inf_fit <- susie_inf(X = scale(data$X), # 7 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 22 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt)
```

```{r, echo = F, warning = F, message = F}
# For the original SuSiE model (with susie_fit$alpha as an L x p matrix):
plot_susie_fit(susie_fit, data, model = "original")

# For the SuSiE-inf model (with susie_inf_fit$PIP as a p x L matrix):
# plot_susie_fit(susie_inf_fit, data, model = "inf")

# For the SuSiE-ash model (with susie_ash_fit$PIP as a p x L matrix):
plot_susie_fit(susie_ash_fit, data, model = "ash")
```

## Scenario 1 Continued (with refine):

We can see by adding the `refine = T` parameter for this situation, we see no change in FDR/Recall. Infact, the contents of the credible sets are identical. 

```{r, echo = F, warning = F, message = F}
susie_fit <- susie(X = data$X, # 8 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T,
      refine = T)

susie_metrics <- calc_metrics(susie_fit, X = data$X, y = data$y, causal = data$causal_indices)
# Create a data frame with the desired metrics
df <- data.frame(
  Method = c("SuSiE", "SuSiE (w/ refine)"),
  FDR = c(0.5, 0.5),
  Recall = c(0.2, 0.2),
  CS_Size = c(15, 15)
)
```

```{r, echo = F}
print(df)
```

## Scenario 2: SuSiE and SuSiE-ash perform nearly identically. SuSiE-inf has perfect FDR and only misses 1 variant compared to the other two.

```{r, include = F}
data <- reproduce_simulation_data(X_subset, seed_val = 47) 
susie_fit <- susie(X = data$X, # 7 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T)

susie_inf_fit <- susie_inf(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt)

susie_metrics <- calc_metrics(susie_fit, X = data$X, y = data$y, causal = data$causal_indices)
susie_inf_metrics <- calc_metrics_inf(susie_inf_fit, X = data$X, y = data$y, causal = data$causal_indices)
susie_ash_metrics <- calc_metrics_inf(susie_ash_fit, X = data$X, y = data$y, causal = data$causal_indices)

# Create a data frame with the desired metrics
df <- data.frame(
  Method = c("SuSiE", "SuSiE-inf", "SuSiE-ash"),
  FDR = c(0.25, 0, 0.25),
  Recall = c(0.3, 0.2, 0.3),
  CS_Size = c(20.25, 9, 20)
)
```


```{r, echo = F}
# Display the data frame
print(df)

```

### Iteration 1

Again, the first iteration will always be equivalent for all three methods. They all construct 3 total CS (2 causals, 1 false positive). The false positive CS is a single variant in moderately high LD (~0.70) with a relatively small effect variable (ranked 6 / 10 in terms of magnitude, largest to smallest).

```{r, include = F}
susie_fit <- susie(X = data$X, # 7 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T,
      max_iter = 1)

susie_inf_fit <- susie_inf(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           maxiter = 1)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt,
                           maxiter = 1)
```

### Iteration 2

For the second iteration, both SuSiE and SuSiE-ash remained the same in terms of CS, while SuSiE-inf got rid of the false positive CS. Now, SuSiE-inf only has 2 CS both true positives. It is important to note that the marginal PIP for this non-causal variant, ID = 546, captured by SuSiE and SuSiE-ash is 0.997 whereas for SuSiE-inf it is ~ 0.83 (already significantly shrunk compared with the first iteration). Here the infinitesimal component seems to be working as intended, however, the ash component missed this.  

```{r, include = F}
susie_fit <- susie(X = data$X, # 7 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T,
      max_iter = 2)

susie_inf_fit <- susie_inf(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           maxiter = 2)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt,
                           maxiter = 2)
```

```{r, echo = F, warning = F, message = F}
# For the original SuSiE model (with susie_fit$alpha as an L x p matrix):
plot_susie_fit(susie_fit, data, model = "original")

# For the SuSiE-inf model (with susie_inf_fit$PIP as a p x L matrix):
plot_susie_fit(susie_inf_fit, data, model = "inf")

# For the SuSiE-ash model (with susie_ash_fit$PIP as a p x L matrix):
plot_susie_fit(susie_ash_fit, data, model = "ash")
```

### Iteration 3

By the third iteration, SuSiE and SuSiE-ash have managed to capture the largest variant by effect size whereas SuSiE-inf missed this. Additionally, SuSiE and SuSiE-ash are slowly starting to reduce the marginal PIP value for the problematic variant described in the first two iterations, decreasing from 0.99 to ~0.85. This variant is still being captured, just the credible set size has increased from 1 to 16. SuSiE-inf still only has 2 credible sets, and is managing to shrink the problematic variant further. However, it is completly missing the largest effect that the other two methods captured.  

```{r, include = F}
susie_fit <- susie(X = data$X, # 7 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T,
      max_iter = 3)

susie_inf_fit <- susie_inf(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           maxiter = 3)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt,
                           maxiter = 3)
```

```{r, echo = F, warning = F, message = F}
# For the original SuSiE model (with susie_fit$alpha as an L x p matrix):
plot_susie_fit(susie_fit, data, model = "original")

# For the SuSiE-inf model (with susie_inf_fit$PIP as a p x L matrix):
plot_susie_fit(susie_inf_fit, data, model = "inf")

# For the SuSiE-ash model (with susie_ash_fit$PIP as a p x L matrix):
plot_susie_fit(susie_ash_fit, data, model = "ash")
```

### Final Iteration

SuSiE converged after 7 iterations, SuSiE-inf after 8, and SuSiE-ash after 8. SuSiE and SuSiE-ash both retained their 4 CS from iteration 3 while further reducing the marginal PIP of the problematic variant down to ~0.01, however, its credible set only grew while never capturing any true casuals. When examining the LD structure of this large CS, all of the variants are in either high (~0.75) to near perfect LD with a single causal variant (as mentioned in the first iteration). SuSiE-inf remained relatively unchanged, it just kept shrinking variants until convergence.

```{r, include = F}
susie_fit <- susie(X = data$X, # 7 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T)

susie_inf_fit <- susie_inf(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq)

susie_ash_fit <- susie_ash_RE_Marg(X = scale(data$X), # 8 iterations
                           y = scale(data$y),
                           L = 20,
                           verbose = F,
                           coverage = 0.95,
                           update_ash_sigma = F,
                           K.length = 20,
                           upper_bound = 2,
                           XtX = XtX,
                           LD = LD,
                           V = V,
                           Dsq = Dsq,
                           VtXt = VtXt)
```

```{r, echo = F, warning = F, message = F}
# For the original SuSiE model (with susie_fit$alpha as an L x p matrix):
plot_susie_fit(susie_fit, data, model = "original")

# For the SuSiE-inf model (with susie_inf_fit$PIP as a p x L matrix):
plot_susie_fit(susie_inf_fit, data, model = "inf")

# For the SuSiE-ash model (with susie_ash_fit$PIP as a p x L matrix):
plot_susie_fit(susie_ash_fit, data, model = "ash")
```

## Scenario 2 Continued (with refine):

We can see by adding the `refine = T` parameter for this situation, we see no change in FDR/Recall. The only change in performance was the slight improvement in average credible set size from 20.25 to 20.

```{r, echo = F, warning = F, message = F}
susie_fit <- susie(X = data$X, # 8 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T)

susie_refine_fit <- susie(X = data$X, # 8 iterations
      y = data$y,
      L = 20,
      standardize = T,
      intercept = T,
      refine = T)

susie_metrics <- calc_metrics(susie_fit, X = data$X, y = data$y, causal = data$causal_indices)

susie_refine_metrics <- calc_metrics(susie_refine_fit, X = data$X, y = data$y, causal = data$causal_indices)
# Create a data frame with the desired metrics
df <- data.frame(
  Method = c("SuSiE", "SuSiE (w/ refine)"),
  FDR = c(0.25, 0.25),
  Recall = c(0.3, 0.3),
  CS_Size = c(20.25, 20)
)
```

```{r, echo = F}
print(df)
```
